<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Vishal Lakha</title>
    <link>https://vishallakha.github.io/tags/python/</link>
    <description>Recent content in Python on Vishal Lakha</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Mar 2022 23:29:21 +0530</lastBuildDate><atom:link href="https://vishallakha.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Siamese Neural Network for Text Similarity</title>
      <link>https://vishallakha.github.io/blog/siamese_text_similarity/</link>
      <pubDate>Thu, 03 Mar 2022 23:29:21 +0530</pubDate>
      
      <guid>https://vishallakha.github.io/blog/siamese_text_similarity/</guid>
      <description>Description I have implemented a Siamese Neural Network for text similarity. It takes two sentences as input and predicts the similarity between them. Here one input comes from the user and the other input is a entire dataset of documents in the data lake. It implements BERT embeddings for both the sentences, takes the average pooling and gives the output as 1024 dimensional vector embeddings. These embeddings are stored in Mongo DB so that they can be easily used again and again without recalculations.</description>
    </item>
    
    <item>
      <title>Data Scrapper with Selenium in Python</title>
      <link>https://vishallakha.github.io/blog/selenium_scrapper/</link>
      <pubDate>Sun, 28 Nov 2021 23:29:21 +0530</pubDate>
      
      <guid>https://vishallakha.github.io/blog/selenium_scrapper/</guid>
      <description>Description I have written Selenium code in Python which can scrap any type of data from any website(dynamic as well as static). It uses Chrome Driver, and waits for given time till an object of a certain class is loaded completely. then it finds all relevant data related to a class name and appends the output in a proper list. This code has the potential to used in any scenario where data needs to be scraped from external sources.</description>
    </item>
    
  </channel>
</rss>
